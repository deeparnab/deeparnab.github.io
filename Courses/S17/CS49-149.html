<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xml:lang="en" xmlns="http://www.w3.org/1999/xhtml" lang="en">

<head>
<link rel="stylesheet" type="text/css" href="test-course.css" id="styleId" text-decoration="none"/>
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Lora">
<title>CS 49/149: Approximation Algorithms, Spring 2017</title> </head>

<body>
<h2>
<font color="black">
CS49/149: Approximation Algorithms, Spring 2017.</font> <br>
</h2>

<b> Instructor:</b> <a style="color:inherit" href="./../../index.htm"> Deeparnab Chakrabarty</a> (Office hours: tba)<br>
<b> TA: </b> <br>
<b> Time:</b> 10A (TR: 10:10am - 12noon)<br> 
<b> Venue:</b> tba<br>
<br>
<hr>  

<br>
<b> Course Description </b> <br>
Many problems arising in computer science are NP-hard and we do not expect polynomial time
algorithms solving them exactly. This has led to the study of approximation algorithms where one relaxes
the goal to return approximate solutions. Over the past three decades, a beautiful theory of approximation
algorithms has emerged. This course provides a broad overview of the main techniques in the area.<br>

<p><b> Background </b><br>
A first course on algorithms and the ability to read and write mathematical proofs will be required.
Prerequisite course: CS 31. Desirable: CS 30, CS 231.

<p>
<b> Recommended Books </b> <br>
There is no required textbook but the following books are highly recommended.
<ul>
<li> <i> The Design of Approximation Algorithms </i> by David Williamson and David Shmoys. <a href="http://www.designofapproxalgs.com/book.pdf"> (pdf) </a>. 
</li>
<li> <i> Approximation Algorithms </i> by Vijay Vazirani. <a href="http://www.cc.gatech.edu/fac/Vijay.Vazirani/book.pdf"> (pdf) </a>
</li>
</ul>

<p>
<b> Evaluation </b><br>
tba

<p> 
<b>Tentative Schedule </b><br>
Each week will be devoted to one or two techniques illustrated on a few problems. There will be
weekly assignments reinforcing these techniques. Below is a tentative schedule and lecture synopses will be posted after class.
<ul>
<li><b>Week 1:</b>  Introduction, Greedy Algorithms, Local Search Algorithms.</li>
<li><b>Week 2:</b> Approximation Schemes </li>
<li><b>Week 3:</b> Linear Programming Relaxations </li>
<li><b>Week 4:</b> Deterministic Rounding </li>
<li><b>Week 5:</b> Iterated Rounding   </li>
<li><b>Week 6:</b> Randomized Rounding </li>
<li><b>Week 7:</b> Primal-Dual Methods </li>
<li><b>Week 8:</b> Semidefinite Programming Relaxations </li>
<li><b>Week 9:</b> Inapproximability </li>
</ul>



<!--
<b> Project. </b> The webpage containing info about the project is up <a href="./Projects.html"> here </a>. 
<br> <br>

<b>Midterm</b> The Midterm will be held in class from 2pm to 5pm on 27th February, 2015. Students can bring in one sheet of paper
with stuff written in <b>their own handwriting</b>. They will have to submit this along with their answer sheets.
<br><br>



<b>Problem Sets</b><br>
We will periodically post assignments with dates when they need to be submitted.
All submissions need to be via email to eo249iisc[AT]gmail.com (save those trees).
We really prefer LaTeXed solutions.
</font> <br>
</font>
<ul>
<li> Problem Set 1, due Feb 6th. <a href="./Problems/prob1.pdf">(pdf)</a> </li>
<li> Problem Set 2, due Feb 20th. <a href="./Problems/prob2.pdf">(pdf)</a> </li>
<li> <strike>Problem Set 3, due Feb 27th. </strike> </li>
<li> Midterm, held Feb 27th <a href = "./Notes/midterm.pdf"> (pdf) </a></li>
<li> Problem Set 4, due Mar 13th. <a href="./Problems/prob4.pdf">(pdf)</a> </li>
<li> Problem Set 5, due Mar 20th. <a href="./Problems/prob5.pdf">(pdf)</a> </li>
<li> Problem Set 6, due Mar 27th. <a href="./Problems/prob6.pdf">(pdf)</a> </li>
<li> Problem Set 7, due Apr 4th. <a href="./Problems/prob7.pdf">(pdf)</a> </li>
<li> Problem Set 8, due Apr 11th. <a href="./Problems/prob8.pdf">(pdf)</a> </li>
<li> Problem Set 9, due Apr 18th. <a href="./Problems/prob9.pdf"> (pdf)</a></li>

</ul>
<br>
<div id="leclist">
  <b> Lectures</b><br>
After (or sometimes before) lectures, we will write a blurb on what we did and provide references
to where the material is from. Sometimes we may provide pdfs of rough notes. Warning: the notes 
are really rough in that we write them in one pass and don't necessarily go over them again.
So they may contain mistakes. If you find one, please let us know and we address them soon.
</font><br>

<ul>
  <li>
  <div id="topic"> <b>Lecture 1 (Jan 16): Introduction, TSP, ATSP.</b> <a href="./Notes/lec1.pdf"> (rough notes)</a> </div>
       <div id="blurb"> 
	   The 1.5-factor approximation algorithm for TSP is due to Christofides from 1976. It is an outstanding <b> open problem </b> to improve this factor.
	   The (log n)-factor approximation algorithm for ATSP is due to <a href="http://www.math.cmu.edu/~af1p/Texfiles/TSPapprox.pdf"> Frieze, Galbiati and Maffioli</a> from 1982. 
	   This was improved in 2011 by Asadpour et al. in <a href="http://web.stanford.edu/~saberi/atsp.pdf">this paper</a>.
	   We may cover this later in the course. A much <a href="http://arxiv.org/abs/1411.4613"> newer</a> awesome result is due to Anari and Oveis Gharan.
	   </div>
  </li>
  <li>
  <div id="topic"> <b>Lecture 2 (Jan 23): Greedy Algorithms.</b> <a href="./Notes/lec2.pdf"> (rough notes)</a> </div>
       <div id="blurb"> 
	   The greedy algorithm for set cover problem has been discovered by many (Johnson, Lovasz, Chvatal, mainly from late seventies). The submodular function maximization is due to 
	   Nemhauser, Wolsey and Fisher from 1978. The submodular set cover was studied by Wolsey in 1982. The unconstrained (not-necessarily monotone) submodular function maximization algorithm 
	   alluded to in class is from this millenium -- a FOCS 2012 paper by Buchbinder, Feldman, Naor and Schwartz.
	</div>
  </li>
  
  <li>
  <div id="topic"> <b>Lecture 3 (Jan 27): Euclidean TSP.</b> <a href="./Notes/lec3.pdf"> (rough notes)</a> </div>
		<div id="blurb">
		Our presentation is mainly drawn from Sanjeev Arora's excellent <a href="http://www.math.tau.ac.il/~michas/arorageo.pdf">survey</a> on approximation algorithms for geometric problems. The current best running time for a Euclidean TSP PTAS is due to <a href="http://www.cs.nyu.edu/~adi/sparse.pdf">Bartal and Gottlieb</a> from 2013. Another related impressive paper is <a href="http://cs.brown.edu/~pnk/publications/tsp2005.pdf">Klein's PTAS</a> for TSP on planar graphs.		
		</div>
  </li>
  
  <li>
  <div id="topic"> <b>Lecture 4 (Jan 30): Linear Programming Relaxations, Facility Location, GAP.</b> <a href="./Notes/lec4.pdf">(rough notes) </a> </div>
       <div id="blurb">
	   The facility location algorithm covered in class is due to Shmoys, Tardos, and Aardal in 1998. This was the first constant factor approximation. The current best factor is 
	   1.488 by Shi Li in <a href="http://ttic.uchicago.edu/~shili/papers/fac-ICALP.pdf"> this paper.</a> The approximation algorithm for GAP is due to Shmoys and Tardos from 1993.
  </div>
  </li>
  
  <li>
  <div id="topic"> <b>Lecture 5 (Feb 6): Iterated Rounding.</b> <a href="./Notes/lec5.pdf">(rough notes) </a> </div>
       <div id="blurb">
	   Iterated rounding in approximation algorithms was introduced by Kamal Jain in his 1998 paper on survivable network design problem which is explored in the problem set 5.
	   The proof done in class is due to Nagarajan, Ravi, and Singh from 2010. There is whole book written on Iterative methods written by Lau, Ravi, and Singh which has a lot of 
	   applications.	   
  </div>
  </li>

  <li>
  <div id="topic"> <b>Lecture 6 (Feb 13): Randomized Rounding.</b> <a href="./Notes/lec6.pdf">(rough notes) </a> </div>
       <div id="blurb">
	   We looked at the use of randomization in approximation algorithms. The use of randomness often makes algorithms easier both to design and analyze. Often such randomized algorithms can be 
	   "derandomized", that is, one can get deterministic algorithms which achieve the same approximation factor, but this is not known to be true in general.
	   (Whether randomness strictly helps in computation is one of the striking questions in computer science.)
	   The algorithm for minimum congestion routing is due to Raghavan and Thomson from 1985 and is one of the first uses of the Chernoff bounds in algorithm design. There has been PLENTY
	   of work following it, and this blurb doesn't suffice to summarize it. The algorithm for GAP is due to Fleischer, Goemans, Mirrokni, and Sviridenko from 2006. 
	   A good reference for concentration inequalities is a book (draft <a href="http://wwwusers.di.uniroma1.it/ale/Papers/master.pdf"> here </a>) by Dubhashi and Panconesi.
  </div>
  </li>
  
  <li>
  <div id="topic"> <b>Lecture 7 (Feb 17): Sublinear Approximation.</b> <a href="./Notes/lec7.pdf">(rough notes) </a></div>
	<div id="blurb">
	We got a glimpse into the world of sublinear algorithms for approximation problems. I had planned to talk about vertex cover and set cover but only got through vertex cover due to discussions. I summarize and clarify that discussion at the end of the posted notes. These topics are covered excellently in Krzysztof Onak's <a href="http://onak.pl/download/publications/phd_thesis.pdf">Ph.D. thesis</a>. More <a href="http://onak.pl/download/publications/Onak_et_al-near_optimal_vertex_cover.pdf">recent work by Onak et. al.</a> improves the query complexity to essentially optimal.
	</div>
  </li>

  <li>
  <div id="topic"> <b>Lecture 8 (Feb 20): Using the Dual.</b> <a href="./Notes/lec8.pdf">(rough notes) </a></div>
	<div id="blurb">
	We looked at the dual of an LP. Then we described Dual fitting and the Primal Dual methodology on Set cover. Then we talked a bit in how the dual can be used to solve LPs with exponentially many variables and polynomially many constraints
	(like the configuration LP from last class). Finally, we looked at how primal-dual, dual fitting and randomized rounding come together to solve the online set cover problem.
	</div>
  </li>

  <li>
  <div id="topic"> <b>Lecture 9 (Mar 6th): Cuts in Graphs.</b> <a href="./Notes/lec9-scribe.pdf">(scribe notes by Saravanan.) </a></div>
	<div id="blurb">
	We looked at three problems -- the minimum s,t cut, the multiway cut, and the multicut problem. The algorithms done in class are due to Calinescu, Karloff and Rabani from 1998. The current best approximation algorithm for the multiway cut problem is (as of 2015 March) 1.2965, and is due to <a href="http://arxiv.org/abs/1309.2729"> Sharma and Vondrak</a>.
	</div>
  </li>
  
  <li>
  <div id="topic"> <b>Lecture 10 (Mar 13th): The Sparsest Cut.</b> <a href="./Notes/lec10-scribe.pdf">(scribe notes by Sayan and Indranil.) </a> </div>
	<div id="blurb">
	We spent most of our time with the uniform sparsest cut and gave a O(log n) approximation algorithm. The result is due to Leighton and Rao from 1988, but the journal version from 1999 
	is a beautiful read, and has many generalizations in it. In particular, it gives O(log n) approximations for what is called the minimum conductance cut. The conductance of a cut is defined
	as the cap(S)/E[S]*E[bar(S)] rather than cap(S)/|S||bar(S)|. 
	
	The general sparsest cut is via metric embeddings and is due to London, Linial, and Rabinovich from 1995. The metric embedding result itself is due to Bourgain. This we didn't have time
	to cover and may do so next class.
	</div>
  </li>
  
  <li>
  <div id="topic"> <b>Lecture 11a (Mar 20th): Bourgain's theorem via padded decomposition.</b> <a href="./Notes/Bourgain.pdf">(rough notes) </a></div>
	<div id="blurb">
	</div>
  </li>
  
  <li>
  <div id="topic"> <b>Lecture 11b (Mar 20th): Semidefinite Programming.</b> <a href="./Notes/lec11-scribe.pdf">(scribe notes by <b> Nitin and Amleshwar</b>) </a></div>
	<div id="blurb">
	We introduced semidefinite programming, a vector relaxation of integer programs. Goemans and Williamson's MAX-CUT algorithm that we saw in class is randomized. The derandomization is nontrivial and is due to Hariharan and Mahajan. An instance with tight integrality gap was given by Feige and Schechtman; the analysis is a piece of gem.
	</div>
  </li>

  
   <li>
  <div id="topic"> <b>Lecture 12 (Mar 27th): Graph coloring and Miniaturization.</b> <a href="./Notes/lec12-scribe.pdf">(scribe notes by <b>Ajith and Dheeraj</b>)</a></div>
	<div id="blurb">
	We discussed Karger, Motwani and Sudan's <a href="http://people.csail.mit.edu/karger/Papers/color.ps">algorithm</a> for coloring 3-colorable graphs. The current best in this line of work is that of <a href="http://drops.dagstuhl.de/opus/volltexte/2014/4479/pdf/37.pdf">Kawarabayashi and Thorup (2014)</a> who achieve O(n^{1.99996}) colors; this paper uses combinatorics to fight the hard case for the previous best SDP-based algorithm. In the second part of the class, we talked about an approach pioneered by Prasad Raghavendra that may turn out to be the "ultimate" rounding method for a wide class of semidefinite relaxations. We discussed it for the MAX-CUT problem. Our presentation is based on the treatment in <a href="http://www.springer.com/gp/book/9783642220142">G&auml;rtner and Matou&#353;ek's book</a>.
	</div>
</li>
  
   <li>
  <div id="topic"> <b>Lecture 13 (Apr 7th): SDP Relaxations for Max CSP.</b> <a href="./Notes/lec13.pdf">(rough notes) </a></div>
	<div id="blurb">
	In Lecture 11b, we'd already given an SDP relaxation for Max-2-SAT. Here, we saw how to make it tighter by adding "triangle inequality constraints". Then, we talked about the so-called canonical SDP relaxation for any Max-k-CSP, which involves scalar variables that give a probability distribution on the local assignment to each clause and vector variables that give a joint distribution on the global assignment to all the variables, as well as "first moment" and "second moment" consistency constraints among the two sets of variables. We also briefly discussed how the SDP can be rounded using the miniaturization method introduced in the last lecture. 
	</div>
</li>
  
     <li>
  <div id="topic"> <b>Lecture 14 (Apr 11th): Proving Hardness of Approximation.</b> <a href="./Notes/lec14-scribe.pdf">(scribe notes by <b>Anurita and Divya</b>) </a></div>
	<div id="blurb">
	We shift to showing hardness of approximation. For standard decision problems, we have the tool of polynomial time reductions and NP-completeness. For optimization problems, we introduced the notion of "gap problems" which are decision problems with a promise (<a href="http://www.wisdom.weizmann.ac.il/~oded/prpr.html">here's</a> a great survey on problems with promised instances).  We looked at reductions from standard NP-complete problems and also approximation-preserving reductions from gap problems. Finally, we introduced PCP's. 
	</div>
	
     <li>
  <div id="topic"> <b>Lecture 15 (Apr 17th): PCP's and Label Cover.</b> (scribe notes by <a href="./Notes/lec15-scribe.pdf"><b>Cressida and Marilyn</b> (part 1)</a> and <a href="./Notes/lec15-scribe2.pdf"><b>Chinmay and Raghav</b> (part 2)</a>)</div>
	<div id="blurb">
	Hastad's theorem on hardness of Gap-E3Lin mentioned in class is from <a href="http://www.nada.kth.se/~johanh/optimalinap.ps">this landmark paper</a>. Hastad also showed that [1,7/8+&epsilon;]-Gap-Max3SAT is NP-hard. We saw in class the weaker fact, through a reduction from Gap-E3Lin, that it is NP-hard to approximate Max3SAT to better than a 7/8 factor. We also introduced the Label Cover problem, discussed its NP-hardness, and saw a reduction from Label Cover to Set Cover. Our presentation was based on Chapter 16 in Williamson-Shmoys.
	</div>
	
	     <li>
  <div id="topic"> <b>Lecture 16 (Apr 25th): Unique Games.</b> <a href="./Notes/lec16-scribe.pdf">(scribe notes by <b>Abhijat and Suprovat</b>) </a></div>
	<div id="blurb">
	The definition of unique games is due to a foresightful <a href="https://www.cs.nyu.edu/~khot/papers/khot-csp.ps">work of Subhash Khot</a>. This <a href="http://ftp.cs.nyu.edu/~khot/papers/UGCSurvey.pdf">survey of his</a> is a very nice overview of the unique games conjecture and the progress so far. We saw a direct reduction from unique games to the multicut problem. We then discussed at a very high level the "long code"-based approach to constructing PCP's. A detailed discussion is out of scope of this course, but there are some great lecture notes available online: <a href="http://courses.cs.washington.edu/courses/cse533/05au/">here</a> and <a href="http://www.cs.cmu.edu/~anupamg/adv-approx/">here</a>. 
	</div>
</li>
  
  
</ul>
-->
</div>


<hr>


